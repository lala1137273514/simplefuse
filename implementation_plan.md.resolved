# SimpleFuse 系统缺失与优化分析报告

基于 Langfuse RepowWiki 内容与 SimpleFuse 当前实现的对比分析

---

## 执行摘要

本报告通过深入分析 Langfuse 的 repowiki 文档与 SimpleFuse 的当前实现，识别出 SimpleFuse 在以下核心领域存在的系统缺失和潜在优化方向。

---

## 一、Langfuse 核心功能概览

### 1.1 追踪系统 (Tracing System)

```mermaid
graph TB
    subgraph "前端"
        FE_TracePage["TracePage.tsx"]
        FE_Trace["Trace.tsx"]
        FE_Graph["TraceGraphView.tsx"]
    end
    subgraph "API 层"
        API_OTEL["/api/public/otel/v1/traces"]
        API_Public["/api/public/ingestion"]
    end
    subgraph "Worker 处理层"
        IS["IngestionService - 事件合并"]
        CW["ClickhouseWriter - 批量写入"]
    end
    subgraph "数据存储"
        CH["ClickHouse"]
        PG["PostgreSQL"]
    end
    FE_TracePage --> FE_Trace
    API_OTEL --> IS
    API_Public --> IS
    IS --> CW
    CW --> CH
```

**Langfuse 追踪系统特点：**
- **多层观测类型**：支持 SPAN、EVENT、GENERATION、AGENT、TOOL、CHAIN、RETRIEVER、EVALUATOR、EMBEDDING、GUARDRAIL 等 10+ 类型
- **事件驱动 + 批量写入架构**：Worker 将事件按时间排序并合并，生成最终记录
- **OpenTelemetry 集成**：原生支持 OTLP Protobuf/JSON 协议
- **高性能数据处理**：指数退避重试、批量缓冲、定时刷新、超大记录截断策略

### 1.2 评估框架 (Evaluation Framework)

- **LLM-as-a-Judge**：自动化 LLM 评估
- **评估模板系统**：可复用的评估配置和提示词模板
- **多来源评分**：API 调用、自动评估、人工标注
- **评分数据类型**：NUMERIC、CATEGORICAL、BOOLEAN
- **异步任务队列**：评估任务的调度、执行和结果存储

### 1.3 数据集管理 (Dataset Management)

- **三层结构**：Dataset → Dataset Item → Dataset Run Item
- **版本控制**：数据项的 validFrom 状态管理
- **源追踪关联**：数据项可关联到源 Trace 和 Observation
- **评估集成**：Dataset Run 与评分系统的闭环

### 1.4 API 体系

- **RESTful API**：完整的 CRUD 操作
- **游标分页**：高效的大数据集查询
- **字段选择**：按需返回字段，减少网络开销
- **批量操作**：支持批量创建、更新、删除

### 1.5 集成能力

- **多 SDK 支持**：Python、JavaScript/TypeScript
- **框架集成**：LangChain、LlamaIndex、Haystack
- **OpenAI 集成**：原生 OpenAI 追踪支持

---

## 二、SimpleFuse 当前实现分析

### 2.1 现有功能

| 功能模块 | 实现状态 | 说明 |
|---------|---------|------|
| Trace 管理 | ✅ 基础实现 | 支持 Dify 数据采集和展示 |
| Langfuse 兼容 Ingestion | ✅ 基础实现 | POST /api/public/ingestion |
| 评测器管理 | ✅ 完整 CRUD | 预置 + 自定义评测器 |
| 评测任务执行 | ✅ 同步执行 | LLM-as-a-Judge |
| 数据集管理 | ✅ 基础 CRUD | 从 Trace 创建数据集 |
| LLM 配置 | ✅ 多 Provider | OpenAI、通义千问等 |

### 2.2 数据模型

```mermaid
erDiagram
    Project ||--o{ Trace : contains
    Project ||--o{ Score : contains
    Project ||--o{ DifyConnection : has
    Project ||--o{ EvaluatorTemplate : has
    Project ||--o{ LlmConfig : has
    Project ||--o{ Dataset : has
    Project ||--o{ EvalConfig : has
    Project ||--o{ EvalJob : has
    Trace ||--o{ Score : scored_by
    Dataset ||--o{ DatasetItem : contains
    EvalConfig ||--o{ EvalJob : creates
```

---

## 三、系统缺失分析

### 3.1 追踪系统

| 缺失项 | 严重程度 | 说明 |
|-------|---------|------|
| **Observation 独立存储** | 🔴 高 | 当前 observations 存储在 Trace.observations JSON 字段，无法独立查询和分析 |
| **观测类型系统** | 🔴 高 | 缺少 SPAN、GENERATION、EVENT 等类型的区分和专属字段 |
| **层级父子关系** | 🟡 中 | 无 parentObservationId 支持，无法构建调用树 |
| **OpenTelemetry 支持** | 🟡 中 | 不支持 OTLP Protobuf 协议 |
| **Token/Cost 细粒度统计** | 🟡 中 | 仅有 totalTokens，缺少 promptTokens、completionTokens、cost 细分 |
| **批量写入 Worker** | 🟡 中 | 缺少独立 Worker 进行事件合并和批量写入 |

### 3.2 评估框架

| 缺失项 | 严重程度 | 说明 |
|-------|---------|------|
| **评估配置复用** | 🟡 中 | 缺少评估模板与配置的解耦 |
| **采样率控制** | 🟢 低 | EvalConfig.samplingRate 已定义但未使用 |
| **自动触发规则** | 🟡 中 | EvalConfig.filterRules 未实现 |
| **评估结果与 Observation 关联** | 🔴 高 | Score 只能关联 Trace，无法关联到具体 Observation |
| **多评分来源标记** | 🟡 中 | 缺少 source 字段区分 API、EVAL、ANNOTATION |

### 3.3 数据集管理

| 缺失项 | 严重程度 | 说明 |
|-------|---------|------|
| **Dataset Run 概念** | 🔴 高 | 缺少运行记录，无法追踪多次评估运行 |
| **Dataset Run Item** | 🔴 高 | 缺少每次运行中每个数据项的详细结果 |
| **期望输出对比** | 🟡 中 | expectedOutput 字段已定义但评估时未使用 |
| **数据项版本控制** | 🟢 低 | 缺少 validFrom 和 status 管理 |

### 3.4 API 体系

| 缺失项 | 严重程度 | 说明 |
|-------|---------|------|
| **公开 REST API** | 🔴 高 | 缺少 /api/public/traces, /api/public/observations 等公开端点 |
| **游标分页** | 🟡 中 | 当前使用 offset 分页，大数据集性能差 |
| **字段选择** | 🟢 低 | 不支持按需返回字段 |
| **批量操作端点** | 🟡 中 | 缺少批量删除等操作 |

### 3.5 集成能力

| 缺失项 | 严重程度 | 说明 |
|-------|---------|------|
| **SDK 支持** | 🔴 高 | 无 Python/JS SDK |
| **非 Dify 集成** | 🟡 中 | 仅支持 Dify，缺少 LangChain 等框架支持 |
| **Webhook 事件** | 🟢 低 | 缺少事件推送能力 |

---

## 四、优化建议

### 4.1 高优先级 (P0) - 核心功能补全

#### 4.1.1 Observation 独立表设计

```sql
-- PostgreSQL (业务数据)
CREATE TABLE observations (
    id VARCHAR(36) PRIMARY KEY,
    trace_id VARCHAR(36) NOT NULL,
    project_id VARCHAR(36) NOT NULL,
    type VARCHAR(20) NOT NULL, -- SPAN | GENERATION | EVENT | RETRIEVAL
    parent_observation_id VARCHAR(36),
    name VARCHAR(255),
    start_time TIMESTAMP NOT NULL,
    end_time TIMESTAMP,
    model VARCHAR(100),
    input TEXT,
    output TEXT,
    metadata JSONB,
    prompt_tokens INTEGER,
    completion_tokens INTEGER,
    total_tokens INTEGER,
    input_cost DECIMAL(10, 6),
    output_cost DECIMAL(10, 6),
    total_cost DECIMAL(10, 6),
    level VARCHAR(20) DEFAULT 'DEFAULT',
    status_message TEXT,
    created_at TIMESTAMP DEFAULT NOW(),
    
    FOREIGN KEY (trace_id) REFERENCES traces(id) ON DELETE CASCADE,
    FOREIGN KEY (project_id) REFERENCES projects(id) ON DELETE CASCADE
);

CREATE INDEX idx_observations_trace ON observations(trace_id);
CREATE INDEX idx_observations_project_time ON observations(project_id, start_time);
CREATE INDEX idx_observations_type ON observations(type);
```

**收益：**
- 支持独立查询任意观测
- 构建完整调用树视图
- 细粒度成本和 Token 统计

#### 4.1.2 Dataset Run 体系

```sql
CREATE TABLE dataset_runs (
    id VARCHAR(36) PRIMARY KEY,
    dataset_id VARCHAR(36) NOT NULL,
    project_id VARCHAR(36) NOT NULL,
    name VARCHAR(100),
    description TEXT,
    metadata JSONB,
    created_at TIMESTAMP DEFAULT NOW(),
    
    FOREIGN KEY (dataset_id) REFERENCES datasets(id) ON DELETE CASCADE
);

CREATE TABLE dataset_run_items (
    id VARCHAR(36) PRIMARY KEY,
    dataset_run_id VARCHAR(36) NOT NULL,
    dataset_item_id VARCHAR(36) NOT NULL,
    trace_id VARCHAR(36),
    observation_id VARCHAR(36),
    input JSONB,
    expected_output JSONB,
    output JSONB,
    error TEXT,
    latency_ms INTEGER,
    total_tokens INTEGER,
    total_cost DECIMAL(10, 6),
    created_at TIMESTAMP DEFAULT NOW(),
    
    FOREIGN KEY (dataset_run_id) REFERENCES dataset_runs(id) ON DELETE CASCADE,
    FOREIGN KEY (dataset_item_id) REFERENCES dataset_items(id) ON DELETE CASCADE
);
```

**收益：**
- 追踪多次评估运行历史
- 对比不同运行的结果差异
- 形成完整的评估闭环

#### 4.1.3 公开 REST API

```
GET  /api/public/traces           # 列表查询
GET  /api/public/traces/:id       # 详情查询
DELETE /api/public/traces/:id     # 删除

GET  /api/public/observations     # 列表查询
GET  /api/public/observations/:id # 详情查询

POST /api/public/scores           # 创建评分
GET  /api/public/scores           # 列表查询
DELETE /api/public/scores/:id     # 删除

GET  /api/public/datasets         # 列表查询
POST /api/public/datasets         # 创建
GET  /api/public/datasets/:name   # 详情查询
```

**收益：**
- 支持外部系统集成
- 与 Langfuse API 兼容
- 便于 SDK 开发

### 4.2 中优先级 (P1) - 功能增强

#### 4.2.1 Score 增强

```diff
model Score {
  id            String   @id
  traceId       String
+ observationId String?  // 支持关联到具体 Observation
  projectId     String
  evaluatorId   String
  evaluatorName String
  score         Float
+ dataType      String   @default("NUMERIC") // NUMERIC | CATEGORICAL | BOOLEAN
+ stringValue   String?  // 分类型评分的字符串值
  reasoning     String?  @db.Text
+ source        String   @default("EVAL") // API | EVAL | ANNOTATION
+ authorUserId  String?  // 人工标注的用户
  evalJobId     String?
  timestamp     DateTime
  createdAt     DateTime @default(now())
}
```

#### 4.2.2 游标分页

```typescript
// 当前: offset 分页
const traces = await prisma.trace.findMany({
  skip: offset,
  take: limit,
})

// 优化: 游标分页
const traces = await prisma.trace.findMany({
  cursor: cursor ? { id: cursor } : undefined,
  take: limit + 1, // 多取一条判断是否有下一页
  orderBy: { timestamp: 'desc' },
})

const hasMore = traces.length > limit
const nextCursor = hasMore ? traces[limit - 1].id : null
```

#### 4.2.3 Worker 架构

```mermaid
graph LR
    A[API 接收事件] --> B[写入 Redis 队列]
    B --> C[Worker 消费]
    C --> D[事件合并]
    D --> E[批量写入 DB]
```

**实现要点：**
- 使用 BullMQ 队列
- 按 traceId 分组事件
- 批量大小 100 条或 5 秒刷新
- 指数退避重试

### 4.3 低优先级 (P2) - 锦上添花

- **OpenTelemetry 支持**：添加 `/api/public/otel/v1/traces` 端点
- **SDK 开发**：Python/JS SDK
- **字段选择**：支持 `?select=id,name,timestamp` 参数
- **Webhook 事件**：评估完成时推送通知

---

## 五、实施路线图

```mermaid
gantt
    title SimpleFuse 功能补全路线图
    dateFormat  YYYY-MM-DD
    
    section P0 - 核心补全
    Observation 独立表           :p0_1, 2026-02-01, 5d
    Dataset Run 体系             :p0_2, after p0_1, 4d
    公开 REST API               :p0_3, after p0_2, 5d
    
    section P1 - 功能增强
    Score 增强                   :p1_1, after p0_3, 3d
    游标分页                     :p1_2, after p1_1, 2d
    Worker 架构                  :p1_3, after p1_2, 5d
    
    section P2 - 锦上添花
    OTEL 支持                    :p2_1, after p1_3, 4d
    SDK 开发                     :p2_2, after p2_1, 7d
```

---

## 六、总结

SimpleFuse 作为轻量级 LLM 观测平台，已具备基础的追踪采集、评测执行能力。但与 Langfuse 完整体系相比，在以下关键领域存在差距：

1. **数据模型粒度**：Observation 未独立存储，限制了细粒度分析能力
2. **评估闭环**：缺少 Dataset Run 体系，无法追踪评估历史
3. **API 开放性**：缺少公开 REST API，限制了外部集成
4. **架构可扩展性**：缺少 Worker 架构，难以应对大规模数据

建议按 P0 → P1 → P2 优先级逐步补全，预计 4-6 周可完成核心功能升级。
